# AI-900

Prazo: February 4, 2023 → February 15, 2023
Status: In progress

# ****Conceitos básicos de IA do Microsoft Azure: Introdução à inteligência artificial****

# ****Noções básicas sobre detecção de anomalias****

## ****Machine learning no Microsoft Azure****

- Machine Learning automatizado
    - Esse recurso permite que quem não é especialista crie rapidamente um modelo de machine learning eficaz com base nos dados.
- Designer do Azure Machine Learning
    - Uma interface gráfica que habilita o desenvolvimento sem código de soluções de machine learning.
- Gerenciamento de dados e computação
    - Armazenamento de dados baseado em nuvem e recursos de computação que os cientistas de dados profissionais podem usar para executar o código de experimento de dados em escala.
- Pipelines
    - Cientistas de dados, engenheiros de software e profissionais de operações de TI podem definir pipelines para orquestrar tarefas de treinamento, implantação e gerenciamento de modelos.

## ****Detecção de anomalias no Microsoft Azure****

- No Microsoft Azure, o serviço **Detector de Anomalias** fornece uma API (interface de programação de aplicativo) que os desenvolvedores podem usar para criar soluções de detecção de anomalias.

# ****Noções básicas sobre a Pesquisa Visual Computacional****

- Classificação de imagens
    - A classificação de imagens envolve treinar um modelo de machine learning para classificar imagens com base no conteúdo delas.
- Detecção de objetos
    - Os modelos de machine learning de detecção de objetos são treinados para classificar objetos individuais dentro de uma imagem e identificar a localização deles com uma caixa delimitadora.
- Segmentação semântica
    - A segmentação semântica é uma técnica avançada de machine learning em que pixels individuais na imagem são classificados de acordo com o objeto ao qual eles pertencem.
- Detecção, análise e reconhecimento facial
    - A detecção facial é uma forma especializada de detecção de objetos que localiza faces humanas em uma imagem.
- OCR (reconhecimento óptico de caracteres)
    - O reconhecimento óptico de caracteres é uma técnica usada para detectar e ler texto em imagens.

## ****Serviços de Pesquisa Visual Computacional no Microsoft Azure****

- **Pesquisa Visual Computacional**
    - Você pode usar esse serviço para analisar imagens e vídeos e extrair descrições, marcas, objetos e texto.
- **Visão Personalizada**
    - Use este serviço para treinar modelos personalizados de classificação de imagens e detecção de objetos usando suas imagens.
- **Detecção Facial**
    - O serviço de Detecção Facial permite que você crie soluções de detecção e reconhecimento facial.
- **Reconhecimento de Formulários**
    - Use esse serviço para extrair informações de formulários e faturas digitalizados.

# ****Noções básicas sobre o processamento de idioma natural****

O NLP permite que você crie um software que pode:

- Analisar e interpretar o texto em documentos, mensagens de email e outras fontes.
- Interpretar o idioma falado e sintetizar as respostas de fala.
- Traduzir automaticamente frases faladas ou escritas entre idiomas.
- Interpretar comandos e determinar as ações apropriadas.

## ****Processamento de idioma natural no Microsoft Azure****

- **Idioma**
    - Use esse serviço para acessar recursos para entender e analisar texto, modelos de linguagem de treinamento que podem entender comandos falados ou baseados em texto e criar aplicativos inteligentes.
- **Tradutor**
    - Use esse serviço para traduzir o texto entre mais de 60 idiomas.
- **Fala**
    - Use esse serviço para reconhecer e sintetizar a fala e para traduzir idiomas falados.
- **Bot do Azure**
    - Esse serviço fornece uma plataforma para IA de conversa, a capacidade de um "agente" de software participar de uma conversa.

# ****Noções básicas sobre a mineração de conhecimento****

Mineração de conhecimento é o termo usado para descrever soluções que envolvem a extração de informações de grandes volumes de dados geralmente não estruturados a fim de criar um repositório de conhecimento pesquisável.

## ****Mineração de conhecimento no Microsoft Azure****

- **Azure Cognitive Search**
    - solução de pesquisa privada e corporativa que tem ferramentas para a criação de índices.
    - 

# ****Noções básicas sobre a IA responsável****

- ****Imparcialidade****
    - Os sistemas de IA devem tratar todas as pessoas de maneira justa.
- ****Confiabilidade e segurança****
    - Os sistemas de IA devem ser executados de maneira confiável e segura.
- ****Privacidade e segurança****
    - Os modelos de machine learning nos quais os sistemas de IA se baseiam dependem de grandes volumes de dados, que podem conter detalhes pessoais que precisam ser mantidos particulares.
- ****Inclusão****
    - Os sistemas de IA devem capacitar todos e envolver as pessoas. O IA deve levar benefícios a todas as camadas da sociedade, independentemente da capacidade física, do sexo, da orientação sexual, da etnia ou de outros fatores.
- ****Transparência****
    - Os sistemas de IA devem ser compreensíveis. Os usuários devem ficar totalmente cientes da finalidade do sistema, de como ele funciona e de quais limitações podem ser esperadas.
- ****Responsabilidade****
    - As pessoas devem ser responsáveis pelos sistemas de IA. Os designers e desenvolvedores de uma solução baseada em IA devem funcionar dentro de uma estrutura de governança e de princípios organizacionais que garantam que a solução cumpra a padrões éticos e legais claramente definidos.

# ****Conceitos básicos de IA do Microsoft Azure: Explorar ferramentas visuais para machine learning****

## ****Usar o machine learning automatizado no Azure Machine Learning****

# ****Usar o machine learning automatizado no Azure Machine Learning****

## Criando um Workspace

1. Entre no [portal do Azure](https://portal.azure.com/) usando suas credenciais da Microsoft.
2. Selecione **＋Criar um recurso**, pesquise por *Machine Learning* e crie um recurso do **Azure Machine Learning** com um plano do *Azure Machine Learning*. Use as configurações a seguir:
    - **Assinatura**: *sua assinatura do Azure*
    - **Grupo de recursos**: *criar ou selecionar um grupo de recursos*
    - **Nome do workspace**: *insira um nome exclusivo para o seu workspace*
    - **Região**: *selecione a região geográfica mais próxima*
    - **Conta de armazenamento**: *observe a nova conta de armazenamento padrão que será criada para o seu workspace*
    - **Cofre de chaves**: *observe o novo cofre de chaves padrão que será criado para o seu workspace*
    - **Application Insights**: *observe o novo recurso do Application Insights padrão que será criado para o seu workspace*
    - **Registro de contêiner**: nenhum (*um será criado automaticamente quando você implantar um modelo em um contêiner pela primeira vez*)
3. Selecione **Examinar + criar**. Aguarde até que o workspace seja criado (isso pode levar alguns minutos). Em seguida, acesse-o no portal.
4. Na página **Visão geral** do workspace, inicie o Estúdio do Azure Machine Learning (ou abra uma nova guia do navegador e acesse [https://ml.azure.com](https://ml.azure.com/)) e entre nele usando sua conta Microsoft.
5. No Estúdio do Azure Machine Learning, selecione as três linhas na parte superior à esquerda para ver as várias páginas na interface. Use essas páginas para gerenciar os recursos no workspace.

Você pode criar quatro tipos de recursos de computação:

- **Instâncias de computação**: estações de trabalho de desenvolvimento que os cientistas de dados podem usar para trabalhar com modelos e dados.
- **Clusters de cálculo**: clusters escalonáveis de máquinas virtuais para processamento sob demanda de código de experimento.
- **Clusters de inferência**: destinos de implantação para serviços preditivos que usam seus modelos treinados.
- **Computação anexada**: links para os recursos de computação do Azure existentes, como máquinas virtuais ou clusters do Azure Databricks.

## ****Criar um cluster de cálculo****

1. Selecione a guia **Clusters de Cálculo** e adicione um novo cluster de cálculo com as configurações a seguir. Você o usará para treinar um modelo de machine learning:
    - **Localização**: *selecione o mesmo que seu workspace. Se essa localização não estiver listada, escolha a mais próxima de você*
    - **Camada de máquina virtual**: dedicada
    - **Tipo de máquina virtual**: CPU
    - **Tamanho da máquina virtual**:
        - Escolha **Selecionar entre todas as opções**
        - Pesquise e selecione **Standard_DS11_v2**
    - Selecione **Avançar**
    - **Nome de computação**: *insira um nome exclusivo*
    - **Número mínimo de nós**: 0
    - **Número máximo de nós**: 2
    - **Segundos de espera antes de reduzir verticalmente**: 120
    - **Habilitar o acesso SSH**: não selecionado
    - Escolha **Criar**
    
    **Dica**
    
    Depois de concluir todo o módulo, siga as instruções em **Limpar** no final do módulo para interromper os recursos de computação. Pare seus recursos de computação para garantir que sua assinatura não seja cobrada.
    

## ****Criar um conjunto de dados****

No Azure Machine Learning, os dados para treinamento de modelos e outras operações geralmente são encapsulados em um objeto chamado de *conjunto de dados*.

1. Exiba os dados separados por vírgula em [https://aka.ms/bike-rentals](https://aka.ms/bike-rentals) no seu navegador da Web.
2. Em [Estúdio do Azure Machine Learning](https://ml.azure.com/), selecione as três linhas no canto superior esquerdo da tela para expandir o painel. Exiba a página **Dados** (em **Ativos**). A página de Dados contém arquivos ou tabelas de dados específicos com os quais você trabalhará no Azure ML. Você também pode criar conjuntos de dados nessa página.
3. Crie um novo conjunto de dados **com base em arquivos da Web** usando as seguintes configurações:
    - **Informações Básicas**:
        - **URL da Web**: [https://aka.ms/bike-rentals](https://aka.ms/bike-rentals)
        - **Nome**: bike-rentals
        - **Tipo de conjunto de dados**: tabular
        - **Descrição**: dados de aluguel de bicicleta
        - **Ignorar validação de dados**: *não selecionar*
    - **Configurações e visualização**:
        - **Formato de arquivo**: delimitado
        - **Delimitador**: vírgula
        - **Codificação**: UTF-8
        - **Cabeçalhos de coluna**: somente o primeiro arquivo tem cabeçalhos
        - **Ignorar linhas**: Nenhum
        - **O conjunto de dados contém dados multilinhas**: *não selecione*
    - **Esquema**:
        - incluir todas as colunas que não sejam **Caminho**
        - Examinar os tipos detectados automaticamente
    - **Confirmar os detalhes**:
        - não criar o perfil do conjunto de dados após a criação
4. Depois que o conjunto de dados tiver sido criado, abra-o e exiba a página **Explorar** para ver uma amostra dos dados. Esses dados contêm as características e os rótulos históricos para aluguéis de bicicletas.

## ****Treinar um modelo de machine learning****

O Azure Machine Learning inclui uma funcionalidade de *machine learning automatizado*
que tenta automaticamente várias técnicas de pré-processamento e algoritmos de treinamento de modelo em paralelo.

## ****Executar um experimento de aprendizado de máquina automatizado****

No Azure Machine Learning, as operações executadas são chamadas de *experimentos*
.

1. No [estúdio do Azure Machine Learning](https://ml.azure.com/), veja a página **ML Automatizado** (em **Criar**).
2. Crie uma execução de ML automatizado com as seguintes configurações:
    - **Selecionar conjunto de dados**:
        - **Conjunto de dados**: bike-rentals
    - **Configurar a execução**:
        - **Nome do novo experimento**: mslearn-bike-rental
        - **Coluna de destino**: rentals (*esse é o rótulo que o modelo será treinado para prever)*
        - **Selecionar cluster de cálculo**: *o cluster de cálculo que você criou anteriormente*
    - **Selecione a tarefa e as configurações:**
        - **Tipo de tarefa**: regressão *(o modelo prevê um valor numérico)*
    
    **Definições de configuração adicionais:**
    
    - **Métrica primária**: selecione **Erro de raiz do erro quadrático médio normalizado***(veremos mais sobre essa métrica mais tarde.)*
    - **Explicar o melhor modelo**: selecionado – *essa opção faz com que o machine learning automatizado calcule a importância do recurso para o melhor modelo, o que possibilita determinar a influência de cada recurso no rótulo previsto.*
    - **Usar todos os modelos com suporte**: selecionado. *Você restringirá o experimento para apenas alguns algoritmos específicos.*
        
        Não
        
    - **Modelos permitidos**: *selecione apenas **RandomForest** e **LightGBM** – normalmente, seria ideal tentar usar o máximo possível, mas cada modelo adicionado aumenta o tempo necessário para executar o experimento.*
    - **Critério de saída**:
        - **Tempo do trabalho de treinamento (horas)**: 0,5 – *encerra o experimento após no máximo 30 minutos.*
        - **Limite de pontuação da métrica**: 0,085 – *se um modelo atingir uma pontuação de métrica de raiz do erro quadrático médio normalizada de 0,085 ou menos, o experimento será encerrado.*
        - **Simultaneidade**: *não alterar*
    - **Configurações de definição de recursos:**
        - **Habilitar definição de recursos**: selecionado – *pré-processar automaticamente os recursos antes do treinamento.*
    
    Clique em **Avançar** para ir ao próximo painel de seleção.
    
    - **[Opcional] Selecionar a validação e o tipo de teste**
        - **Tipo de validação**: Automático
        - **Testar o conjuntos de dados (versão prévia)**: nenhum conjunto de dados de teste necessário
3. Quando você terminar de enviar os detalhes de execução do ML automatizado, ele será iniciado automaticamente. Aguarde até que o status de execução mude de *Preparando* para *Em execução*.
4. Quando o status da execução for alterado para *Em execução*, exiba a guia **Modelos** e observe conforme cada combinação possível de algoritmo de treinamento e etapas de pré-processamento é tentada e conforme o desempenho do modelo resultante é avaliado. A página é atualizada automaticamente em intervalos, mas você também pode selecionar **↻ Atualizar**. Pode levar dez minutos em média para os modelos começarem a aparecer, pois os nós de cluster precisam ser inicializados para que o treinamento seja iniciado.

## ****Examinar o melhor modelo****

- O **Histograma Residual** mostra a frequência de intervalos de valores residuais.
    - Os valores residuais representam a variância entre os valores previstos e verdadeiros que não podem ser explicados pelo modelo, em outras palavras, os erros.
- O gráfico **Previsto versus Verdadeiro**  deve mostrar uma tendência diagonal em que o valor previsto se correlaciona de perto com o valor verdadeiro.
- **Explicações**
    - Selecione uma ID de explicação e escolha **Importância agregada do recurso**. O gráfico mostra a quantidade de cada recurso no conjunto de dados que influencia a previsão de rótulo

# ****Implantar um modelo como um serviço****

No Azure Machine Learning, você pode implantar um serviço como ACI (Instâncias de Contêiner do Azure) ou em um cluster do AKS (Serviço de Kubernetes do Azure).

- Para cenários de produção, é recomendável uma implantação do AKS, para a qual você precisa criar um destino de computação do *cluster de inferência*.
- ACI é um destino de implantação adequado para teste e não exige que você crie um cluster de inferência.

## ****Criar um modelo de regressão com o designer do Azure Machine Learning****

## ****Identificar cenários de aprendizado de máquina de regressão****

- A regressão é uma forma de aprendizado de máquina usada para entender as relações entre variáveis para prever um resultado desejado.
- A regressão prevê um *rótulo* numérico ou um resultado com base em variáveis ou *funcionalidades*.
- A regressão é um exemplo de uma técnica de machine learning *supervisionada* na qual você treina um modelo usando dados que incluem as características e os valores conhecidos para o rótulo, de modo que o modelo aprende a *ajustar* as combinações de recursos para o rótulo.
- Em seguida, após a conclusão do treinamento, você pode usar o modelo treinado para prever rótulos para novos itens para os quais o rótulo é desconhecido.

****Cenários para modelos de machine learning de regressão****

- Usando características de casas, como metragem quadrada e número de quartos, para prever os preços das casas.
- Usando características de condições agrícolas, como clima e qualidade do solo, para prever o rendimento das culturas.
- Usando características de uma campanha anterior, como logs de publicidade, para prever cliques futuros em anúncios.

### ****Azure Machine Learning Studio****

- O Estúdio do Azure Machine Learning é um portal da Web para soluções de machine learning no Azure.

### ****Computação do Azure Machine Learning****

- Os destinos de computação são recursos baseados em nuvem nos quais é possível executar os processos de treinamento de modelos e de exploração de dados.
- No [Estúdio do Azure Machine Learning](https://ml.azure.com/), você pode gerenciar os destinos de computação para as suas atividades de ciência de dados. Você pode criar quatro tipos de recursos de computação:
    - **Instâncias de computação**: estações de trabalho de desenvolvimento que os cientistas de dados podem usar para trabalhar com modelos e dados.
    - **Clusters de cálculo**: clusters escalonáveis de máquinas virtuais para processamento sob demanda de código de experimento.
    - **Clusters de inferência**: destinos de implantação para serviços preditivos que usam seus modelos treinados.
    - **Computação anexada**: links para os recursos de computação do Azure existentes, como máquinas virtuais ou clusters do Azure Databricks.

### Designer ******do Azure Machine Learning****

- você pode usar para treinar, testar e implantar modelos de machine learning.

### ****Pipelines****

- Os pipelines permitem que você organize, gerencie e reutilize fluxos de trabalho complexos de aprendizado de máquina entre projetos e usuários.

### ****Componentes****

- Um componente do Azure Machine Learning encapsula uma etapa no pipeline de aprendizado de máquina.
- Você pode pensar em um componente como uma função de programação e como um bloco de construção para pipelines do Azure Machine Learning.

### ****Conjuntos de dados****

Você pode criar ativos de dados na página **Dados** por meio de arquivos locais, de um armazenamento de dados, de arquivos Web e do Open Datasets.

### ****Trabalhos****

- Um trabalho do Azure Machine Learning (ML) executa uma tarefa em um destino de computação especificado.
- Os trabalhos habilitam o acompanhamento sistemático para fluxos de trabalho e experimentação de aprendizado de máquina.

## ****Noções básicas de etapas de regressão****

1. **Preparar dados**: identifique as funcionalidades e o rótulo em um conjunto de dados. Pré-processe ou limpe e transforme os dados, conforme necessário.
2. **Treinar modelo**: divida os dados em dois grupos, um conjunto de treinamento e um conjunto de validação. Treine um modelo de machine learning usando o conjunto de dados de treinamento. Teste o modelo de machine learning para obter desempenho, usando o conjunto de dados de validação.
    1. Você usará o componente *Modelo de Pontuação* do **designer** para gerar o valor do rótulo de classe previsto.
3. **Avaliar desempenho**: compare quanto as previsões do modelo se aproximam dos rótulos conhecidos.
    1. **MAE (erro médio absoluto)**: a diferença média entre os valores previstos e os valores reais. Esse valor se baseia nas mesmas unidades que o rótulo, neste caso, dólares. Quanto menor esse valor, melhor a qualidade da previsão do modelo.
    2. **REQM (raiz do erro quadrático médio)**: A raiz quadrada da diferença quadrática média entre os valores previstos e verdadeiros. O resultado é uma métrica baseada na mesma unidade que o rótulo (dólares). Quando comparado ao MAE (acima), uma diferença maior indica maior variância nos erros individuais (por exemplo, com alguns erros sendo muito pequenos, enquanto outros são grandes).
    3. **RSE (erro ao quadrado relativo)**: uma métrica relativa entre 0 e 1 com base no quadrado das diferenças entre os valores previstos e os reais. Quanto mais próximo de 0 essa métrica for, melhor será o desempenho do modelo. Como essa métrica é relativa, ela pode ser usada para comparar modelos em que os rótulos estão em unidades diferentes.
    4. **RAE (erro absoluto relativo)**: uma métrica relativa entre 0 e 1 com base nas diferenças absolutas entre os valores previstos e os reais. Quanto mais próximo de 0 essa métrica for, melhor será o desempenho do modelo. Assim como ocorre com o RSE, essa métrica pode ser usada para comparar modelos em que os rótulos estão em unidades diferentes.
    5. **Coeficiente de determinação (R2)**: essa métrica é mais comumente conhecida como *R-quadrado* e resume a quantidade de variância entre os valores previstos e verdadeiros que é explicada pelo modelo. Quanto mais próximo de 1 for esse valor, melhor será o desempenho do modelo.
4. **Implantar um serviço preditivo**: depois de treinar um modelo de machine learning, você precisará converter o pipeline de treinamento em um pipeline de inferência em tempo real. Em seguida, você pode implantar o modelo como aplicativo em um servidor ou dispositivo para que outras pessoas possam usá-lo.

## ****Criar um modelo de classificação com o designer do Azure Machine Learning****

# ****Identificar cenários de machine learning de classificação****

A *classificação* é uma forma de machine learning que é usada para prever a qual categoria ou *classe* um item pertence.

****Cenários para modelos de machine learning de classificação****

- Usando dados clínicos para prever se um paciente ficará doente ou não.
- Usar dados históricos para prever se o sentimento do texto é positivo, negativo ou neutro.
- Usando características de pequenas empresas para prever se um novo empreendimento terá sucesso.

# ****Entender etapas de classificação****

## ****Noções básicas de etapas de regressão****

1. **Preparar dados**: identifique as funcionalidades e o rótulo em um conjunto de dados. Pré-processe ou limpe e transforme os dados, conforme necessário.
2. **Treinar modelo**: divida os dados em dois grupos, um conjunto de treinamento e um conjunto de validação. Treine um modelo de machine learning usando o conjunto de dados de treinamento. Teste o modelo de machine learning para obter desempenho, usando o conjunto de dados de validação.
    1. Você usará o componente *Modelo de Pontuação* do **designer** para gerar o valor do rótulo de classe previsto.
3. **Avaliar desempenho**: compare quanto as previsões do modelo se aproximam dos rótulos conhecidos.
    - ****Matriz de confusão****
        
        A matriz de confusão é uma ferramenta usada para avaliar a qualidade das previsões de um modelo de classificação. Ele compara os rótulos previstos com os rótulos reais.
        
        1. ***Verdadeiro Positivo***: o modelo prevê que o paciente tem diabetes, e o paciente realmente tem diabetes.
        2. ***Falso Positivo***: o modelo prevê que o paciente tem diabetes, mas o paciente não tem diabetes.
        3. ***Falso Negativo***: O modelo prevê que o paciente não tem diabetes, mas o paciente realmente tem diabetes.
        4. ***Verdadeiro Negativo***: O modelo prevê que o paciente não tem diabetes, e o paciente realmente não tem diabetes.
        
        As métricas que podem ser derivadas da matriz de confusão incluem:
        
        - **Exatidão**: o número de previsões corretas (verdadeiros positivos + verdadeiros negativos) dividido pelo número total de previsões.
        - **Precisão**: o número de casos classificados como positivos que são realmente positivos (o número de verdadeiros positivos) dividido pelo número de verdadeiros positivos, somados aos falsos positivos.
        - **Recall**: a fração de casos positivos identificados corretamente (o número de verdadeiros positivos) dividido pelo número de verdadeiros positivos somados aos falsos negativos. Outro termo para *recall* é **Taxa de verdadeiros positivos**
        - **Medida f**: uma métrica geral que combina exatidão e recall.
    - ****Escolhendo um limite****
        
        O Designer tem um ***controle deslizante de limite*** útil para examinar como o desempenho do modelo seria alterado de acordo com o limite definido.
        
    - ****Curva ROC e métrica AUC****
        
        **curva ROC:** 
        
        - Outro termo para *recall* é **Taxa de verdadeiros positivos** e tem uma métrica correspondente chamada **Taxa de falsos positivos**, que mede o número de casos negativos identificados incorretamente como positivos em comparação com o número de casos negativos reais.
        - O gráfico dessas métricas entre si para cada valor de limite possível entre 0 e 1 resulta em uma curva conhecida como **curva ROC** (ROC significa *característica operacional do receptor*, mas a maioria dos cientistas de dados a chama apenas de curva ROC).
        - Quanto maior a *área sob a curva* da métrica **AUC** (que pode ser qualquer valor de 0 a 1), melhor é o desempenho do modelo.
        - **Um valor de AUC de 0,5 é o que você esperaria com a previsão aleatória de um modelo binário.**
4. **Implantar um serviço preditivo**: depois de treinar um modelo de machine learning, você precisará converter o pipeline de treinamento em um pipeline de inferência em tempo real. Em seguida, você pode implantar o modelo como aplicativo em um servidor ou dispositivo para que outras pessoas possam usá-lo.

## ****Criar um Modelo de Clustering com o designer do Azure Machine Learning****

# ****Criar e executar um pipeline de treinamento****

### ****Avaliar um modelo de clustering****

- A avaliação de um modelo de clustering é dificultada pelo fato de que não há valores *verdadeiros* conhecidos para as atribuições de cluster. Um modelo de clustering bem-sucedido alcança um bom nível de separação entre os itens em cada cluster, portanto, precisamos de métricas para nos ajudar a medir essa separação.
- As métricas em cada linha são:
    - **Distância Média ao Outro Centro**: indica a proximidade, em média, de cada ponto no cluster aos centroides de todos os outros clusters.
    - **Distância Média ao Centro do Cluster**: indica a proximidade, em média, de cada ponto no cluster ao centroide do cluster.
    - **Número de Pontos**: o número de pontos atribuídos ao cluster.
    - **Distância Máxima ao Centro do Cluster**: o máximo das distâncias entre cada ponto e o centroide do cluster desse ponto. Quando esse número é alto, o cluster pode estar altamente disperso. Essa estatística, em conjunto com a **Distância Média ao Centro do Cluster**, ajuda a determinar o *espalhamento* do cluster.

# ****Conceitos básicos de IA do Microsoft Azure: Explorar a pesquisa visual computacional****

## ****Analisar imagens com o serviço de Pesquisa Visual Computacional****

### ****Recursos do Azure para a Pesquisa Visual Computacional****

Para usar o serviço de Pesquisa Visual Computacional é preciso criar um recurso para ele na sua assinatura do Azure. Você pode usar qualquer um dos seguintes tipos de recurso:

- **Pesquisa Visual Computacional**: um recurso específico para o serviço de Pesquisa Visual Computacional. Use esse tipo de recurso se você não pretender usar nenhum outro serviço cognitivo ou se desejar controlar a utilização e os custos do recurso de Pesquisa Visual Computacional separadamente.
- **Serviços Cognitivos**: um recurso de serviços cognitivos gerais que inclui a Pesquisa Visual Computacional além de muitos outros serviços cognitivos, como Análise de Texto, Tradução de Texto e outros. Use esse tipo de recurso se planejar usar vários serviços cognitivos e desejar simplificar a administração e o desenvolvimento.

Seja qual for o tipo de recurso que você escolher criar, ele fornecerá duas informações necessárias para usá-lo:

- Uma **chave** usada para autenticar aplicativos cliente.
- Um **ponto de extremidade** que fornece o endereço HTTP no qual seu recurso pode ser acessado.

### ****Como analisar imagens com o serviço de Pesquisa Visual Computacional****

- ****Descrição de uma imagem****
    - Dependendo do conteúdo da imagem, o serviço pode retornar vários resultados ou frases.
    - Cada frase retornada terá uma pontuação de confiança associada, indicando quão confiante o algoritmo está na descrição fornecida.
    - As frases de confiança mais altas serão listadas primeiro.
- ****Marcação de recursos visuais****
    - As descrições de imagem geradas pela Pesquisa Visual Computacional se baseiam em um conjunto de milhares de objetos reconhecíveis, que podem ser usados para sugerir ***marcas*** para a imagem.
    - Essas marcas podem ser associadas à imagem como metadados que resumem os atributos da imagem.
    - Elas serão particularmente úteis se você quiser indexar uma imagem junto com um conjunto de termos-chave que podem ser usados para pesquisar imagens com atributos ou conteúdos específicos.
- ****Detecção de objetos****
    - A funcionalidade de detecção de objetos é semelhante à marcação, pois o serviço pode identificar objetos comuns.
    - Entretanto, em vez de marcar ou fornecer marcas apenas para os objetos reconhecidos, esse serviço também pode retornar o que é conhecido como coordenadas da caixa delimitadora.
- ****Detecção de marcas****
    - Esse recurso fornece a capacidade de identificar marcas comerciais.
    - O serviço tem um banco de dados existente de milhares de logotipos globalmente reconhecidos de marcas comerciais de produtos.
- ****Detecção de rostos****
    - O serviço de Pesquisa Visual Computacional pode detectar e analisar rostos humanos em uma imagem, incluindo a capacidade de determinar a idade e um retângulo de caixa delimitadora na localização dos rostos.
    
- ****Categorização da imagem****
    - O serviço usa uma hierarquia pai/filho com um conjunto limitado "atual" de categorias.
    
- ****Detecção de conteúdo específico de domínio****
    - Ao categorizar uma imagem, o serviço Pesquisa Visual Computacional dá suporte a dois modelos de domínio especializados:
        - **Celebridades** – O serviço inclui um modelo que foi treinado para identificar milhares de celebridades conhecidas do mundo do esporte, do entretenimento e de negócios.
        - **Pontos de referência** – O serviço pode identificar pontos de referência famosos, como o Taj Mahal e a Estátua da Liberdade.
    
- ****Reconhecimento óptico de caracteres****
    - O serviço de Pesquisa Visual Computacional pode usar funcionalidades de OCR (reconhecimento óptico de caracteres) para detectar texto impresso e manuscrito em imagens.
    
- ****Funcionalidades adicionais****
    - Detectar tipos de imagem – Por exemplo, identificar imagens de clip-art ou desenhos de linha.
    - Detectar esquemas de cores da imagem – Especificamente, identificar as cores dominantes no primeiro plano, no segundo plano e em geral em uma imagem.
    - Gerar miniaturas – Criar versões pequenas de imagens.
    - Moderar conteúdo – Detectar imagens que contêm conteúdo para adulto ou que ilustram cenas violentas ou sanguinolentas.
    

## ****Classificar imagens com o Serviço de Visão Personalizada****

### ****Usos da classificação de imagens****

Alguns usos potenciais para a classificação de imagem incluem:

- **Identificação do produto**: execução de pesquisas visuais para produtos específicos em pesquisas online ou, ainda, na loja usando um dispositivo móvel.
- **Investigação de desastre**: identificação da infraestrutura principal para grandes esforços de preparação para desastre. Por exemplo, identificar pontes e estradas em imagens aéreas pode auxiliar as equipes de ajuda humanitária a planejarem com antecedência em regiões que não estão bem mapeadas.
- **Diagnóstico médico**: a avaliação de imagens de dispositivos de raio-X ou RM pode classificar rapidamente os problemas específicos encontrados como tumores cancerígenos ou muitas outras condições médicas relacionadas ao diagnóstico de imagens médicas.

### ****Entender a classificação****

Os modelos de machine learning de classificação usam um conjunto de entradas, que chamamos de *recursos*, para calcular uma pontuação de probabilidade para cada classe possível e prever um *rótulo* que indica a classe mais provável à qual um objeto pertence.

****Entender a classificação de imagem****

- Para criar um modelo de classificação de imagem, você precisa de dados que consistem em recursos e seus rótulos.
- Os dados existentes são um conjunto de imagens categorizadas.
- As imagens digitais são compostas por uma matriz de valores de pixel e eles são usados como recursos para treinar o modelo com base nas classes de imagem conhecidas.

****Serviço de Visão Personalizada do Azure****

A maioria das soluções de classificação de imagens modernas baseia-se em técnicas de *aprendizado profundo* que fazem uso de *CNNs* (redes neurais convolucionais) para descobrir padrões nos pixels que correspondem a classes específicas.

Técnicas comuns usadas para treinar modelos de classificação de imagens foram encapsuladas no serviço cognitivo de **Visão Personalizada** no Microsoft Azure.

### ****Introdução à classificação de imagens no Azure****

Você pode executar a classificação de imagens usando o Serviço de Visão Personalizada, disponível como parte das ofertas dos Serviços Cognitivos do Azure. Isso é geralmente mais fácil e rápido do que escrever o próprio código de treinamento de modelo e permite que pessoas com pouca ou nenhuma experiência em machine learning criem uma solução de classificação de imagens efetiva.

****Recursos do Azure para a Visão Personalizada****

A criação de uma solução de classificação de imagens com Visão Personalizada é composta por duas tarefas principais. Primeiro, você precisa usar imagens existentes para treinar o modelo, depois, precisa publicar o modelo para que os aplicativos cliente possam usá-lo para gerar previsões. Para cada uma dessas tarefas, você precisa de um recurso em sua assinatura do Azure. É possível usar os seguintes tipos de recursos: 

- **Visão Personalizada**: Um recurso dedicado para o serviço de visão personalizado, que pode ser um recurso de *treinamento*, uma *previsão* ou *ambos*.
- **Serviços Cognitivos**: um recurso geral dos serviços cognitivas que inclui a Visão Personalizada junto com muitos outros serviços cognitivos. Você pode usar esse tipo de recurso para *treinamento*, *previsão* ou ambos.

- A separação de recursos de treinamento e previsão será útil quando você quiser acompanhar a utilização de recursos para o treinamento de modelos separadamente de aplicativos cliente usando o modelo para prever classes de imagem.
- A abordagem mais simples é usar um recurso geral dos Serviços Cognitivos para treinamento e previsão.
- Se você quiser criar um recurso de Visão Personalizada, escolha *treinamento*, *previsão* ou *ambos*.
- Também é possível usar uma abordagem de combinação e correspondência na qual você usa um recurso de Visão Personalizada dedicado para treinamento, mas implanta seu modelo em um recurso dos Serviços Cognitivos para previsão.
    - Para que isso funcione, os recursos de treinamento e previsão precisam ser criados na mesma região.

### ****Treinamento de modelos****

- Para treinar um modelo de classificação, você precisa carregar imagens para seu recurso de treinamento e rotulá-las com os rótulos de classe apropriados. Em seguida, você precisa treinar o modelo e avaliar os resultados de treinamento.
- Você pode executar essas tarefas no *portal da Visão Personalizada* ou, se tiver a experiência de codificação necessária, poderá usar um dos SDKs (Software Development Kits) específicos a uma linguagem de programação do Serviço de Visão Personalizada.
- Uma das principais considerações quando você usa imagens para classificação é garantir que você tenha imagens suficientes dos objetos em questão e que essas imagens devam ser do objeto de vários ângulos diferentes.

### ****Avaliação de modelos****

O desempenho do modelo treinado é indicado pelas seguintes métricas de avaliação:

- **Precisão**: Qual percentual das previsões de classe feitas pelo modelo estava correta? Por exemplo, se o modelo prevê que dez imagens são laranjas, das quais oito eram mesmo laranjas, a precisão é de 0,8 (80%).
- **Recall**: Que percentual de previsões de classe o modelo identificou corretamente? Por exemplo, se houver dez imagens de maçãs e o modelo tiver encontrado sete delas, o recall será de 0,7 (70%).
- **AP (precisão média)**: uma métrica geral que leva em consideração a precisão e o recall).

### ****Usar o modelo para previsão****

Para usar seu modelo, os desenvolvedores de aplicativos cliente precisam das seguintes informações:

- **ID de Projeto**: a ID exclusiva do projeto de Visão Personalizada que você criou para treinar o modelo.
- **Nome do modelo**: o nome que você atribuiu ao modelo durante a publicação.
- **Ponto de extremidade de previsão**: o endereço HTTP dos pontos de extremidade do recurso de *previsão* no qual você publicou o modelo (***não*** o recurso de treinamento).
- **Chave de previsão**: a chave de autenticação do recurso de *previsão* no qual você publicou o modelo (***não*** o recurso de treinamento).

## ****Detectar objetos em imagens com o Serviço de Visão Personalizada****

### ****Usos da detecção de objetos****

Alguns aplicativos de exemplo da detecção de objetos incluem:

- **Verificação da segurança da construção**: avaliar a segurança de uma construção analisando as imagens de seu interior em busca de extintores de incêndios ou outros equipamentos de emergência.
- **Auxílio de direção**: a criação de software para carros ou veículos autônomos com funcionalidades de *indicação de faixa*. O software pode detectar se há um carro em outra faixa e se o carro do motorista está dentro das próprias faixas.
- **Detecção de tumores**: imagens médicas como uma MRI ou raios-X, que podem detectar objetos conhecidos para chegar a um diagnóstico médico.

**O que é a detecção de objetos?**
Um modelo de detecção de objetos pode ser usado para identificar os objetos individuais de uma imagem e retornar as seguintes informações:

- A *classe* de cada objeto identificado na imagem.
- A pontuação de probabilidade da classificação de objetos (que você pode interpretar como a *confiança* de a classe prevista estar correta)
- As coordenadas de uma *caixa delimitadora* para cada objeto.

### ****Introdução à detecção de objetos no Azure****

Você pode executar a classificação de imagens usando o Serviço de Visão Personalizada, disponível como parte das ofertas dos Serviços Cognitivos do Azure. Isso é geralmente mais fácil e rápido do que escrever o próprio código de treinamento de modelo e permite que pessoas com pouca ou nenhuma experiência em machine learning criem uma solução de classificação de imagens efetiva.

****Recursos do Azure para a Visão Personalizada****

A criação de uma solução de classificação de imagens com Visão Personalizada é composta por duas tarefas principais. Primeiro, você precisa usar imagens existentes para treinar o modelo, depois, precisa publicar o modelo para que os aplicativos cliente possam usá-lo para gerar previsões. Para cada uma dessas tarefas, você precisa de um recurso em sua assinatura do Azure. É possível usar os seguintes tipos de recursos: 

- **Visão Personalizada**: Um recurso dedicado para o serviço de visão personalizado, que pode ser um recurso de *treinamento*, uma *previsão* ou *ambos*.
- **Serviços Cognitivos**: um recurso geral dos serviços cognitivas que inclui a Visão Personalizada junto com muitos outros serviços cognitivos. Você pode usar esse tipo de recurso para *treinamento*, *previsão* ou ambos.

- A separação de recursos de treinamento e previsão será útil quando você quiser acompanhar a utilização de recursos para o treinamento de modelos separadamente de aplicativos cliente usando o modelo para prever classes de imagem.
- A abordagem mais simples é usar um recurso geral dos Serviços Cognitivos para treinamento e previsão.
- Se você quiser criar um recurso de Visão Personalizada, escolha *treinamento*, *previsão* ou *ambos*.
- Também é possível usar uma abordagem de combinação e correspondência na qual você usa um recurso de Visão Personalizada dedicado para treinamento, mas implanta seu modelo em um recurso dos Serviços Cognitivos para previsão.
    - Para que isso funcione, os recursos de treinamento e previsão precisam ser criados na mesma região.

****Marcação de imagens****

Para treinar um modelo de detecção de objetos, marque as classes e as coordenadas da caixa delimitadora em um conjunto de imagens de treinamento.

- Esse processo pode ser demorado, mas o *portal de Visão Personalizada* fornece uma interface gráfica que o torna simples. A interface vai sugerir automaticamente áreas da imagem em que objetos discretos são detectados e você vai poder aplicar um rótulo de classe a essas caixas delimitadoras sugeridas ou arrastar para ajustar a área da caixa delimitadora.
- Além disso, após a marcação e o treinamento com um conjunto de dados inicial, o serviço de Pesquisa Visual Computacional pode usar a ***marcação inteligente*** para sugerir classes e caixas delimitadoras para imagens adicionadas ao conjunto de dados de treinamento.

### ****Treinamento de modelos****

- Para treinar um modelo de classificação, você precisa carregar imagens para seu recurso de treinamento e rotulá-las com os rótulos de classe apropriados. Em seguida, você precisa treinar o modelo e avaliar os resultados de treinamento.
- Você pode executar essas tarefas no *portal da Visão Personalizada* ou, se tiver a experiência de codificação necessária, poderá usar um dos SDKs (Software Development Kits) específicos a uma linguagem de programação do Serviço de Visão Personalizada.
- Uma das principais considerações quando você usa imagens para classificação é garantir que você tenha imagens suficientes dos objetos em questão e que essas imagens devam ser do objeto de vários ângulos diferentes.

## ****Detectar e analisar rostos com o serviço de Detecção Facial****

### ****Detecção facial****

A detecção facial envolve a identificação de regiões de uma imagem que contêm um rosto humano, normalmente retornando as coordenadas da *caixa delimitadora* que formam um retângulo em volta do rosto

****Análise facial****

Mudando além da detecção facial simples, alguns algoritmos também podem retornar outras informações, como pontos de referência faciais (nariz, olhos, sobrancelhas, lábios e outros).

****Reconhecimento de rosto****

Uma outra aplicação de análise facial é treinar um modelo de machine learning para identificar indivíduos conhecidos com base nos traços do rosto deles.

### ****Usos de detecção e análise facial****

- O reconhecimento do rosto para fins de segurança pode ser usado na criação de aplicativos de segurança e cada vez mais é usado em sistemas operacionais de smartphones para desbloquear esses dispositivos.
- Mídia social – o reconhecimento do rosto pode ser usado para marcar automaticamente os amigos conhecidos em fotos.
- Monitoramento inteligente – por exemplo, um automóvel pode incluir um sistema que monitora o rosto do motorista para determinar se ele está olhando para a estrada, olhando para um dispositivo móvel ou mostrando sinais de cansaço.
- Publicidade – a análise de rostos em uma imagem pode ajudar a direcionar anúncios para um público-alvo demográfico apropriado.
- Pessoas desaparecidas – usando sistemas de câmeras públicas, o reconhecimento do rosto pode ser usado para identificar se uma pessoa desaparecida está no quadro da imagem.
- Validação de identidade – útil em portas de quiosques de entrada em que uma pessoa tem uma permissão de entrada especial.

### ****Introdução à análise de Detecção Facial no Azure****

O Microsoft Azure fornece vários serviços cognitivos que você pode usar para detectar e analisar rostos, incluindo:

- **Pesquisa Visual Computacional**, que oferece detecção facial e algumas análises faciais básicas, como retornar as coordenadas da caixa delimitadora em torno de uma imagem.
- **Video Indexer**, que você pode usar para detectar e identificar rostos em um vídeo.
- **Detecção Facial**, que oferece algoritmos pré-criados capazes de detectar, reconhecer e analisar rostos.

****Detecção Facial****

A Detecção Facial pode retornar as coordenadas de retângulo de rostos humanos encontrados em uma imagem, bem como uma série de atributos relacionados a esses rostos, tais como:

- **Desfoque**: quão desfocado está o rosto (que pode ser uma indicação da probabilidade de o rosto ser o foco principal da imagem)
- **Exposição**: define aspectos como subexposto ou superexposto e aplica-se ao rosto na imagem e não à exposição geral da imagem
- **Óculos**: se a pessoa está usando óculos
- **Posição da cabeça**: orientação da cabeça em um espaço 3D
- **Ruído**: refere-se ao ruído visual na imagem. Se você tiver tirado uma foto com uma configuração ISO alta para um ambiente mais escuro, observará esse ruído na imagem. A imagem parece granulada ou cheia de pontos minúsculos que tornam a imagem menos clara
- **Oclusão**: determina se pode haver objetos bloqueando o rosto na imagem

****Uso responsável de IA****

Qualquer pessoa pode usar o serviço de Detecção Facial para:

- Detectar o local dos rostos em uma imagem
- Determinar se um rosto está usando óculos
- Determinar se há oclusão, desfoque, ruído ou exposição excessiva/insuficiente para qualquer um dos rostos
- Retornar as coordenadas de pose de cabeça para cada rosto em uma imagem

A Política de Acesso Limitado exige que os clientes [enviem um formulário de admissão](https://aka.ms/facerecognition)
 para acessar os recursos de serviço de Detecção Facial adicionais, incluindo:

- A capacidade de comparar rostos em busca de similaridade
- A capacidade de identificar indivíduos nomeados em uma imagem

****Recursos do Azure para a Detecção Facial****

Para usar a Detecção Facial, você precisa criar um dos seguintes tipos de recurso em sua assinatura do Azure:

- **Rosto**: use esse tipo de recurso específico se você não pretender usar nenhum outro serviço cognitivo ou se desejar controlar a utilização e os custos da Detecção Facial separadamente.
- **Serviços Cognitivos**: um recurso de serviços cognitivos gerais que inclui a Pesquisa Visual Computacional, além de muitos outros serviços cognitivos, como Visão Personalizada, Reconhecimento de Formulários, Linguagem e outros. Use esse tipo de recurso se planejar usar vários serviços cognitivos e desejar simplificar a administração e o desenvolvimento.

Seja qual for o tipo de recurso que você escolher criar, ele fornecerá duas informações necessárias para usá-lo:

- Uma **chave** usada para autenticar aplicativos cliente.
- Um **ponto de extremidade** que fornece o endereço HTTP no qual seu recurso pode ser acessado.

****Dicas para resultados mais precisos****

- formato de imagem – os formatos de imagem compatíveis são JPEG, PNG, GIF e BMP
- tamanho do arquivo – 6 MB ou inferior
- intervalo de tamanho do rosto – de 36 x 36 até 4096 x 4096. Rostos menores ou maiores não serão detectados
- outros problemas – a detecção facial pode ser prejudicada por ângulos extremos de rosto, oclusão (objetos que bloqueiam o rosto, como óculos escuros ou uma das mãos). Os melhores resultados são obtidos quando os rostos estão em posição totalmente frontal ou o mais próximo possível dessa posição.

## ****Ler texto com o serviço de Pesquisa Visual Computacional****

### ****Introdução à API de Leitura no Microsoft Azure****

****A API de Leitura****

- A API de Leitura usa os modelos de reconhecimento mais recentes e é otimizada para imagens que têm uma quantidade significativa de texto ou um ruído visual considerável.
- Como a API de Leitura pode trabalhar com documentos grandes, ela funciona de forma assíncrona para não bloquear seu aplicativo enquanto ele está lendo o conteúdo e retornando resultados para seu aplicativo.
- Isso significa que, para usar a API de Leitura, seu aplicativo deve usar um processo de três etapas:
    1. Enviar uma imagem para a API e recuperar uma *ID de operação* em resposta.
    2. Usa a ID da operação para verificar o status da operação de análise de imagem e aguardar até que ela seja concluída.
    3. Recuperar os resultados da operação.
- Os resultados da API de Leitura são organizados na seguinte hierarquia:
    - **Páginas**: uma para cada página de texto, incluindo informações sobre o tamanho e a orientação da página.
    - **Linhas**: as linhas de texto em uma página.
    - **Palavras** - As palavras em uma linha de texto, incluindo as coordenadas da caixa delimitadora e o próprio texto.

## ****Analisar recibos com o serviço Reconhecimento de Formulários****

### ****Introdução****

Usando o Reconhecimento de Formulários podemos inserir uma imagem de um recibo e retornar informações úteis que possam ser necessárias em um pedido de reembolso de despesas, incluindo:

- O nome, o endereço e o número de telefone do comerciante.
- A data e a hora da compra.
- A quantidade e o preço de cada item adquirido.
- Os valores de subtotal, imposto e total.

### ****Introdução à análise de recibo no Azure****

- O **Reconhecimento de Formulários** no Azure fornece funcionalidades de processamento inteligente de formulários que você pode usar para automatizar o processamento de dados em documentos como formulários, faturas e recibos.
- O Reconhecimento de Formulários dá suporte ao processamento automático de documentos por meio de:
    - **Um modelo de recibo pré-criado** que é fornecido pronto para uso e é treinado para reconhecer e extrair dados de recibos de vendas.
    - **Modelos personalizados**, que permitem extrair o que é conhecido como pares de chave/valor e dados de tabela de formulários. Os modelos personalizados são treinados usando seus dados, o que ajuda a personalizar esse modelo para seus formulários específicos. Começando com apenas cinco exemplos de seus formulários, é possível treinar o modelo personalizado. Após o primeiro exercício de treinamento, é possível avaliar os resultados e considerar se você precisa adicionar mais amostras e treinar novamente.

****Usar o modelo de recibo pré-criado****

- **Atualmente, o modelo de recibo pré-criado foi projetado para reconhecer recibos comuns, em inglês, que são comuns para os EUA. Os exemplos são recibos usados em restaurantes, locais de varejo e estações de gás. O modelo é capaz de extrair informações importantes da guia de recibo:**
    - hora da transação
    - data da transação
    - informações do comerciante
    - impostos pagos
    - valores totais do recibos
    - outras informações pertinentes que estejam presentes no recibo
    - todo o texto no recibo também é reconhecido e retornado

Use as diretrizes a seguir para obter os melhores resultados ao usar um modelo personalizado.

- As imagens precisam estar nos formatos JPEG, PNG, BMP, PDF ou TIFF
- O tamanho do arquivo precisa ser inferior a 50 MB
- Tamanho da imagem entre 50 x 50 pixels e 10.000 x 10.000 pixels
- Para documentos em PDF, não maior do que 17 polegadas x 17 polegadas

# ****Conceitos básicos de IA do Microsoft Azure: Explorar o processamento de idioma natural****

## ****Analisar o texto com o serviço de linguagem****

### ****Técnicas de Análise de Texto****

Há algumas técnicas conhecidas que poderão ser usadas para criar um software de análise de texto, incluindo:

- Análise estatística dos termos usados no texto. Por exemplo, remover "palavras irrelevantes" comuns (como "o" ou "um", que revela poucas informações semânticas sobre o texto) e executar uma *análise de frequência* das palavras restantes (contando com que frequência cada palavra aparece) poderá fornecer pistas sobre o assunto principal do texto.
- Ao estender a análise de frequência para frases de vários termos, comumente conhecidas como *N-grams* (uma frase de duas palavras equivale a um *bi-gram*, uma frase de três palavras equivale a um *tri-gram* e assim por diante).
- Aplicar algoritmos de *stemming* ou *lematização* para normalizar palavras antes de contá-las. Para que palavras como "power", "powered" e "powerful" sejam interpretadas como a mesma palavra.
- Aplicar regras de estrutura linguística para analisar frases. Por exemplo, dividir frases em estruturas semelhantes a árvores, como uma *frase nominal*, que contém *substantivos*, *verbos*, *adjetivos* e assim por diante.
- A codificação de palavras ou termos como recursos numéricos poderão ser usados para treinar um modelo de machine learning. Por exemplo, para classificar um documento de texto com base nos termos que ele contém. Essa técnica geralmente é usada para executar uma *análise de sentimentos*, na qual um documento será classificado como positivo ou negativo.
- Criar modelos *vetorizados* que capturam as relações semânticas entre as palavras, atribuindo a elas locais no espaço n-dimensional. Essa técnica de modelagem pode atribuir valores às palavras "flor" e "planta" que as aproximem, enquanto "skate" pode receber um valor que a distancie.

### ****Introdução à análise de texto****

O serviço de linguagem faz parte das ofertas de Serviços Cognitivos do Azure que poderão executar um processamento avançado de linguagem natural sobre textos brutos.

****Detecção de idioma****

Use a funcionalidade de detecção de idioma do serviço de linguagem para identificar o idioma no qual o texto está escrito.

- Será possível enviar vários documentos por vez para análise
- Para cada documento enviado, o serviço detectará:
    - O nome do idioma (por exemplo, "inglês").
    - O código ISO 6391 do idioma (por exemplo, "in").
    - Uma pontuação que indicará um nível de confiança na detecção de idioma.
    
- O foco do serviço de detecção de idioma será o idioma ***predominante***
 no texto.

****Conteúdo ambíguo ou com vários idiomas****

Alguns textos poderão ser ambíguos por natureza ou ter um conteúdo com vários idiomas. Essas situações poderão ser um desafio para o serviço.

****Análise de sentimento****

Essa funcionalidade será útil para detectar sentimentos positivos e negativos em mídias sociais, análises dos clientes, fóruns de discussão e muito mais.

Ao usar o modelo de classificação predefinido de machine learning, o serviço avaliará o texto e retornará uma pontuação de sentimentos com um intervalo entre 0 a 1, sendo que valores próximos de 1 serão considerados sentimentos positivos. As pontuações próximas ao meio do intervalo (0,5) serão consideradas neutras ou indeterminadas.

Caso o código de idioma seja inserido errado o algoritmo irá retornar 0,5 por padrão.

****Extração de frases-chave****

O conceito de extração de frases-chave é avaliar o texto de documentos e identificar os principais pontos de discussão deles.

****Reconhecimento de entidade****

- É possível fornecer ao serviço de linguagem texto não estruturado e ele retornará uma lista de *entidades* no texto que ele reconhece.
- O serviço também poderá fornecer links para que seja possível obter mais informações sobre essa entidade na Web.

## ****Como usar o reconhecimento de fala e a sintetização de voz****

### ****Introdução à Fala no Azure****

O Microsoft Azure oferece funcionalidades de reconhecimento de fala e sintetização de voz por meio do Serviço Cognitivo de **Fala**, que inclui as seguintes APIs (interfaces de programação de aplicativo):

- API de **Conversão de Fala em Texto**
- API de **Conversão de Texto em Fala**

### ****API de Conversão de Fala em Texto****

- É possível usar a API de Conversão de Fala em Texto para executar a transcrição em lote ou em tempo real de um áudio em formato de texto.
- A fonte de áudio da transcrição poderá ser uma fluxo de áudio em tempo real de um microfone ou um arquivo de áudio.
- O modelo será otimizado para dois cenários: conversação e ditado.
- Também será possível criar e treinar seus modelos personalizados, incluindo acústica, linguagem e pronúncia, caso os modelos predefinidos da Microsoft não forneçam o que você precisa.

****Transcrição em tempo real****

- A Conversão de Fala em Texto em tempo real permite transcrever texto em transmissões de áudio.
- Para que a transcrição em tempo real funcione, seu aplicativo deverá escutar o áudio de entrada de um microfone ou outra fonte de entrada de áudio, como um arquivo de áudio.
- O código do aplicativo transmitirá o áudio para o serviço que retornará o texto transcrito.

****Transcrição em lote****

- A transcrição em lote deverá ser executada de maneira assíncrona, pois os trabalhos em lote são agendados *com base no melhor esforço*.
- Será possível transmitir arquivos de áudio com um URI de SAS (assinatura de acesso compartilhado) e receber resultados de transcrição de maneira assíncrona.

### ****API de Conversão de Texto em Fala****

A API de Conversão de Texto em Fala permite converter a entrada de texto em uma fala audível, que poderá ser reproduzida de modo direto por meio de um alto-falante de computador ou gravada em um arquivo de áudio.

## ****Traduzir texto e fala****

### ****Tradução de fala e texto****

- A *tradução de texto* pode ser usada para converter documentos de um idioma para outro, traduzir comunicações por email provenientes de governos estrangeiros e até mesmo traduzir páginas da Web na Internet.
- A *tradução de fala* é usada para converter entre idiomas falados, às vezes diretamente (conversão de fala em fala) e, às vezes, pela tradução para um formato de texto intermediário (conversão de fala em texto).

### ****Traduzir texto com o serviço de Tradução****

- O serviço de Tradução é fácil de integrar com aplicativos, sites, ferramentas e soluções. O serviço usa um modelo de NMT (tradução automática neural) para tradução, que analisa o contexto semântico do texto e gera uma tradução mais precisa e completa.
- Ao usar o serviço de Tradução, você pode especificar um idioma de ***origem***
 e vários idiomas de ***destino***, permitindo traduzir um documento de origem para vários idiomas de modo simultâneo.
- Como alternativa, você pode especificar variantes culturais de idiomas complementando o código de idioma com o código cultural 3166-1 correspondente – por exemplo, *en-US*
 para inglês dos EUA, *en-GB* para o inglês britânico ou *fr-CA* para o francês canadense.

****Configurações opcionais****

A API de Tradução oferece algumas configurações opcionais para ajudar a ajustar os resultados retornados, incluindo:

- **Filtro de conteúdo ofensivo**. Sem nenhuma configuração, o serviço traduzirá o texto de entrada sem filtrar o conteúdo ofensivo. Os níveis de conteúdo ofensivo são normalmente específicos à cultura, mas você pode controlar a tradução dele marcando o texto traduzido como ofensivo ou omitindo-o nos resultados.
- **Tradução seletiva**. Você pode marcar o conteúdo para que ele não seja traduzido. Por exemplo, você pode querer marcar o código, um nome de marca ou uma palavra/frase que não faça sentido quando localizada.

### ****Tradução de fala com o serviço de Fala****

O serviço de Fala inclui as seguintes APIs (interface de programação de aplicativo):

- **Conversão de fala em texto**: usada para transcrever fala de uma fonte de áudio em formato de texto.
- **Conversão de texto em fala**: usada para gerar áudio falado com base em uma fonte de texto.
- **Tradução de Fala**: usada para traduzir fala em um idioma para texto ou fala em outro.

É possível usar a API de **Tradução de Fala** para traduzir áudio falado de uma fonte de streaming, como um microfone ou um arquivo de áudio, e retornar a tradução como um texto ou stream de áudio.

**Observação:**

- Para usar o serviço Tradutor, não é preciso usar o ponto de extremidade do Serviço Cognitivo. Um ponto de extremidade global apenas para o serviço Tradutor é fornecido.

## ****Criar um modelo de linguagem com Compreensão da Linguagem Coloquial****

### ****Introdução****

****Declarações****

Enunciado é um exemplo de algo que um usuário poderá dizer e que seu aplicativo deverá interpretar. Por exemplo: "*Ligar o ventilador.*" ou "*Ligar as luzes.*"

****Entidades****

Uma entidade é um item ao qual um enunciado se refere. Como **ventilador** e **luz.** É possível considerar as entidades **ventilador** e **luz** como instâncias específicas de uma entidade geral do **dispositivo**.

****Intenções****

- Uma intenção representa a finalidade ou meta expressada no enunciado de um usuário. Por exemplo, para os enunciados considerados anteriormente, a intenção é ativar um dispositivo. Portanto, em seu aplicativo de Compreensão da Linguagem Coloquial, é possível definir a intenção **TurnOn** que está relacionada a esses enunciados.
- A intenção ***None*** tem uma importância exclusiva. Sempre será necessário considerar usar a intenção None para ajudar a lidar com enunciados que não conseguem mapear os enunciados inseridos.
- A intenção None será considerada um fallback e normalmente é usada para fornecer uma resposta genérica aos usuários quando as solicitações não correspondem a nenhuma outra intenção.

**Dica**

Em um aplicativo de Compreensão da Linguagem Coloquial, a intenção **None** será criada, porém a finalidade estará vazia. A intenção None é uma intenção necessária e não pode ser excluída nem renomeada. Preencha-a com declarações que estejam fora de seu domínio.

### ****Introdução à Compreensão da Linguagem Coloquial****

Criar um aplicativo com a Compreensão da Linguagem Coloquial consiste em duas tarefas principais:

- Primeiro, será necessário definir entidades, intenções e enunciados que serão usados para treinar o modelo de linguagem, mencionado como *criação* do modelo.
- Depois será necessário publicar o modelo para que os aplicativos cliente possam usá-lo para obter a *previsão*
 de intenção e entidade com base na entrada do usuário.

### ****Criação****

- A Compreensão da Linguagem Coloquial fornece uma coleção abrangente de *domínios*
predefinidos que incluem intenções e entidades predefinidas para cenários comuns. Você poderá usá-los como ponto de partida para seu modelo. Também será possível criar suas entidades e intenções.
    - Será possível criar entidades e intenções em qualquer ordem.
    - Será possível criar uma intenção e selecionar palavras nos enunciados de exemplo que você definir para criar entidades para eles.
    - Ou será possível criar as entidades com antecedência e depois mapeá-las para obter palavras nos enunciados enquanto estiver criando as intenções.
- É possível escrever códigos para definir os elementos do modelo, no entanto, na maioria dos casos, é mais fácil criar seu modelo usando o portal de Reconhecimento vocal – uma interface baseada na Web para criar e gerenciar aplicativos de Compreensão da Linguagem Coloquial.
    - **Dica:** A melhor prática é usar o Portal de linguagem para criação e usar o SDK em previsões de runtime.

### ****Como criar intenções****

- Defina as intenções com base nas ações que um usuário deseja executar com seu aplicativo.
- Caso uma intenção possa ser aplicada a várias entidades, certifique-se de incluir enunciados de exemplo para cada possível entidade.
- Além disso, garanta cada entidade esteja identificada no enunciado.

### ****Como criar entidades****

Há quatro tipos de entidades:

- **Machine-Learned**: entidades que seu modelo aprenderá durante o treinamento do contexto nos enunciados de exemplo que você fornecerá.
- **Lista**: entidades definidas como uma hierarquia de listas e sublistas. Por exemplo, uma lista de **dispositivos** poderá incluir as sublistas **luzes** e **ventiladores**. Para cada entrada de lista, será possível especificar sinônimos, como **lâmpadas** para **luzes**.
- **RegEx**: entidades definidas como uma *expressão regular* que descrevem um padrão. Por exemplo, será possível definir um padrão como **[0-9]{3}-[0-9]{3}-[0-9]{4}** para números de telefone no formato ***555-123-4567***.
- **Pattern.any**: entidades usadas com *padrões* para definir entidades complexas que poderão ser difíceis de extrair dos enunciados de exemplo.

## ****Criar um bot com o serviço de Linguagem e o Serviço de Bot do Azure****

### ****Introdução ao serviço de Linguagem e ao Serviço de Bot do Azure****

- **Serviço de Linguagem**
    - O serviço de Linguagem inclui um recurso de resposta às perguntas personalizadas, que permite definir uma base de conhecimento de pares de pergunta e resposta que podem ser consultados usando entrada de linguagem natural.
    - **Observação:** A funcionalidade de respostas às perguntas no serviço de Linguagem é uma versão mais recente do serviço QnA Maker, que ainda está disponível como um serviço separado.
- **Serviço de Bot do Azure**. Um serviço que oferece uma estrutura para desenvolver, publicar e gerenciar bots no Azure.

### ****Criar uma base de dados de conhecimento de respostas às perguntas personalizadas****

- Você pode usar o recurso de respostas às perguntas personalizadas do *Language Studio*
 para criar, treinar, publicar e gerenciar bases de dados de conhecimento.
    - **Observação:** É possível escrever código para criar e gerenciar bases de dados de conhecimento usando o SDK ou a API REST do serviço de Linguagem. No entanto, na maioria dos cenários, é mais fácil usar o Language Studio.
    

****Usar a base de dados de conhecimento****

Para acessar a base de dados de conhecimento, os aplicativos clientes exigem:

- A ID da base de dados de conhecimento
- O ponto de extremidade da base de dados de conhecimento
- A chave de autorização da base de dados de conhecimento

### ****Criar um bot com o Serviço de Bot do Azure****

- É possível criar um bot personalizado usando o SDK do Microsoft Bot Framework para escrever código que controla o fluxo de conversa e se integra à sua base de dados de conhecimento.
- Uma abordagem mais fácil é usar a funcionalidade de criação automática de bot, que permite criar um bot para a sua base de dados de conhecimento implantada e publicá-lo como um aplicativo do Serviço de Bot do Azure com apenas alguns cliques.

****Estender e configurar o bot****

Depois de criar o bot, você pode gerenciá-lo no portal do Azure, em que você pode:

- Aumentar a funcionalidade do bot adicionando código personalizado.
- Testar o bot em uma interface de teste interativa.
- Configurar o registro em log, a análise e a integração com outros serviços.

Para atualizações simples, você pode editar o código do bot diretamente no portal do Azure. No entanto, para uma personalização mais abrangente, você pode baixar o código-fonte e editá-lo localmente, republicando o bot diretamente no Azure quando estiver pronto.

# ****Conceitos básicos de IA do Microsoft Azure: Explorar o apoio à decisão****

## ****Introdução ao Detector de Anomalias****

### ****Introdução****

A detecção de anomalias é uma técnica de inteligência artificial usada para determinar se os valores de uma série estão dentro dos parâmetros esperados.

O Detector de Anomalias do Azure é um serviço baseado em nuvem que ajuda a monitorar e detectar anormalidades em seus dados de série temporal e em tempo real.

### ****Serviço do Detector de Anomalias do Azure****

- O Detector de Anomalias faz parte da categoria Serviços de Decisão nos Serviços Cognitivos do Azure.
- Ele é um serviço baseado em nuvem que permite monitorar e detectar anomalias em dados de série temporal.
- Você pode usar a API REST para integrar o Detector de Anomalias a seus aplicativos com relativa facilidade.

****Formato de dados****

- O serviço do Detector de Anomalias aceita dados no formato JSON.
- Você pode usar qualquer dado numérico que tenha registrado ao longo do tempo.
- **O serviço dá suporte a um máximo de 8.640 pontos de dados.**

****Recomendações de consistência de dados****

- Caso seus dados tenham valores ausentes na sequência, considere seguir as recomendações abaixo.
    - A amostragem ocorre a cada poucos minutos e tem menos de 10% do número esperado de pontos ausentes. Nesse caso, o impacto deve ser insignificante nos resultados da detecção.
    - Caso você tenha mais de 10% de pontos ausentes, há opções para ajudar a "preencher" o conjunto de dados. Considere usar um método de interpolação linear para preencher os valores ausentes e completar o conjunto de dados. Isso preencherá as lacunas com valores distribuídos uniformemente.

### ****Quando usar o Detector de Anomalias****

****Detecção em lote****

- A detecção em lote envolve a aplicação do algoritmo a uma série de dados inteira de uma vez.
- É melhor usar a detecção em lote quando seus dados contêm:
    - Dados de série temporal de tendência simples, com picos ou quedas ocasionais
    - Dados da série temporal sazonal com anomalias ocasionais
        - A sazonalidade é considerada um padrão que ocorre em intervalos regulares em seus dados. Os padrões horários, diários ou mensais são exemplos disso. Usar dados sazonais e especificar um período para esse padrão pode ajudar a reduzir a latência na detecção.
        

****Detecção em tempo real.****

- A detecção em tempo real usa dados de streaming comparando os pontos de dados vistos anteriormente com o último ponto de dados para determinar se o último é uma anomalia.

# ****Conceitos básicos de IA do Microsoft Azure: Explorar a mineração de conhecimento****

## ****Introdução ao Azure Cognitive Search****

Seus recursos do Azure Cognitive Search e dos Serviços Cognitivos precisam estar na mesma localização.

### ****O que é o Azure Cognitive Search?****

- O Azure Cognitive Search oferece a infraestrutura e as ferramentas para criar soluções de pesquisa que extraem dados de uma variedade de documentos estruturados, semiestruturados e não estruturados.

****Recursos do Azure Cognitive Search****

- **Dados de qualquer fonte**: o Azure Cognitive Search aceita dados de qualquer fonte fornecidos no formato JSON, com suporte para rastreamento automático de fontes de dados selecionadas no Azure.
- **Análise de texto e pesquisa de texto completo**: o Azure Cognitive Search oferece recursos de pesquisa de texto completo que oferecem suporte tanto para uma consulta simples como para sintaxe de consulta Lucene completa.
- **Pesquisa habilitada por IA**: o Azure Cognitive Search tem funcionalidades cognitivas de IA incorporadas para análise de imagem e texto do conteúdo bruto.
- **Multilíngue**: o Azure Cognitive Search oferece análise linguística para 56 idiomas para processar com inteligência a linguística específica a um idioma ou correspondência fonética. Os processadores de linguagem natural disponíveis no Azure Cognitive Search são os mesmos usados pelo Bing e pelo Office.
- **Habilitados geograficamente**: o Azure Cognitive Search dá suporte à filtragem de pesquisa geográfica com base na proximidade a uma localização física.
- **Experiência do usuário configurável**: o Azure Cognitive Search tem vários recursos para melhorar a experiência do usuário, incluindo preenchimento automático, sugestão automática, paginação e realce de ocorrências.

### ****Identificar elementos de uma solução de pesquisa****

- Uma solução típica do Azure Cognitive Search começa com uma fonte de dados que contém os artefatos de dados que você deseja pesquisar.
- O formato de dados compatível com o Cognitive Search é JSON. Seja qual for a fonte dos dados, se você puder fornecê-los como um documento JSON, o mecanismo de pesquisa poderá indexá-los.
- Se os dados residirem em uma fonte de dados com suporte, você poderá usar um indexador para automatizar a ingestão de dados, incluindo a serialização de JSON de dados de origem em formatos nativos.
- Você pode anexar um conjunto de habilidades que aplique uma sequência de habilidades de IA para enriquecer os dados, tornando-os mais pesquisáveis.

### ****Usar um conjunto de habilidades para definir um pipeline de enriquecimento****

- O processamento de IA é obtido pela adição e pela combinação de habilidades em um conjunto de habilidades.
- Um conjunto de habilidades define as operações que extraem e enriquecem os dados para torná-los pesquisáveis.
- Essas habilidades de IA podem ser habilidades internas, como tradução de texto, OCR (reconhecimento óptico de caracteres) ou habilidades personalizadas fornecidas por você.

****Habilidades internas****

- As habilidades internas são baseadas em modelos pré-treinados da Microsoft, o que significa que não é possível treinar o modelo usando dados de treinamento próprios.
- As habilidades internas se enquadram nestas categorias:
    - **Habilidades de processamento de linguagem natural**
    : com essas habilidades, o texto não estruturado é mapeado como campos pesquisáveis e filtráveis em um índice.
    - **Habilidades de processamento de imagem**
    : cria representações de texto do conteúdo da imagem, tornando-o pesquisável por meio das funcionalidades de consulta do Azure Cognitive Search.

### Índices

- Um índice do Azure Cognitive Search pode ser visto como um contêiner de documentos pesquisáveis.
- Conceitualmente, você pode considerar um índice como uma tabela, e cada linha da tabela representa um documento.
- As tabelas nas colunas podem ser pensadas como equivalentes aos campos em um documento.
- Colunas têm tipos de dados, da mesma forma que os campos nos documentos.

****Esquema de índice****

- No Azure Cognitive Search, um índice é uma coleção persistente de documentos JSON e outros tipos de conteúdo usados para habilitar a funcionalidade de pesquisa.
- O índice inclui uma definição da estrutura dos dados nesses documentos, chamada de esquema.

****Atributos de índice****

- O Azure Cognitive Search precisa saber como você deseja pesquisar e exibir os campos nos documentos.
- Você especifica isso atribuindo atributos, ou comportamentos, a esses campos.

Os índices mais eficientes usam apenas os comportamentos necessários. Se você esquecer de definir um comportamento necessário em um campo, a única maneira de obter esse recurso será recompilar o índice.

### ****Usar um indexador para criar um índice****

- Para que os documentos sejam indexados no armazenamento do Azure, eles precisam ser exportados do tipo de arquivo original para JSON.
- Para exportar dados em qualquer formato para JSON e carregá-los em um índice, usamos um indexador.
- Para criar documentos de pesquisa, você pode gerar documentos JSON com o código do aplicativo ou pode usar o indexador do Azure para exportar documentos recebidos para o JSON.
- O Azure Cognitive Search permite criar e carregar documentos JSON em um índice de duas maneiras:
- **Método de push**: os dados JSON são enviados por push a um índice de pesquisa por meio da API REST ou do SDK do .NET. O envio de dados por push tem mais flexibilidade, pois não tem nenhuma restrição quanto ao tipo de fonte de dados, à localização nem à frequência de execução.
- **Método de pull**: os indexadores do serviço Pesquisa podem efetuar pull de dados de fontes de dados populares do Azure e, se necessário, exportar esses dados para o JSON, se ainda não estiverem nesse formato.

****Usar o método de pull para carregar dados com um indexador****

- O indexador do Azure Cognitive Search é um rastreador que extrai o texto pesquisável e os metadados de uma fonte de dados externa do Azure e popula um índice de pesquisa usando mapeamentos de campo a campo entre os dados de origem e o índice.

****Monitoramento e verificação de importação de dados****

- A página de visão geral de serviços de pesquisa tem um painel que permite que você veja rapidamente a integridade do serviço de pesquisa.

### ****Persistir dados enriquecidos em um repositório de conhecimento****

- Um repositório de conhecimento é o armazenamento persistente de um conteúdo enriquecido.
- A finalidade de um repositório de conhecimento é armazenar em um contêiner os dados gerados com base no enriquecimento de IA.
- Os conjuntos de habilidades movem um documento por meio de uma sequência de enriquecimentos que invocam transformações.
- O resultado pode ser um índice de pesquisa ou projeções em um repositório de conhecimento.
- Um repositório de conhecimento pode conter um ou mais dos três tipos de projeção dos dados extraídos:
    - Projeções de tabela são usadas para estruturar os dados extraídos em um esquema relacional para consulta e visualização
    - Projeções de objeto são documentos JSON que representam cada entidade de dados
    - Projeções de arquivo são usadas para armazenar imagens extraídas no formato JPG

### ****Criar um índice no portal do Azure****

Antes de usar um indexador para criar um índice, você precisa disponibilizar os dados em uma fonte de dados com suporte. As fontes de dados com suporte são:

- Cosmos DB (API de SQL)
- SQL do Azure (banco de dados, instância gerenciada e SQL Server em uma VM do Azure)
- Armazenamento do Azure (Armazenamento de Blobs, Armazenamento de Tabelas, ADLS Gen2)

### ****Consultar dados em um índice do Azure Cognitive Search****

- Depois de criarmos o índice, poderemos executar consultas.
    - É importante entender que o esquema de índice determina quais consultas podem ser respondidas.